{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c464192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7b1657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===weight shape===  torch.Size([5, 4, 6])\n",
      "===output shape===  torch.Size([7, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "layer = torch.nn.Conv1d(in_channels = 4, out_channels = 5, kernel_size = 6, bias = False)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "input = torch.rand(7,4,8)\n",
    "print(F\"===output shape===  {layer(input).shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7439ba",
   "metadata": {},
   "source": [
    "7 is batch_size, which consists.\n",
    "5 is out_channels from layer\n",
    "3 is 8(from input) - 6(kernel_size from layer) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49bf11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 4., 8.]]])\n",
      "===weight shape===  torch.Size([1, 1, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1.0000, 0.1100]]], requires_grad=True)\n",
      "===result===  tensor([[[1.2200, 2.4400, 4.8800]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 1, basic without bias.\n",
    "input = torch.tensor([1, 2, 4, 8], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 2, bias = False)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1., 0.11], dtype = torch.float32, requires_grad = True).view(layer.weight.shape))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35609d41",
   "metadata": {},
   "source": [
    "1        2         4        8\n",
    " 1  0.11   1  0.11   1  0.11\n",
    "  1+0.22   2+0.44    4+0.88\n",
    "   1.22     2.44      4.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc30d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3.]]])\n",
      "===weight shape===  torch.Size([1, 1, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1., 1.]]], requires_grad=True)\n",
      "===bias shape===  torch.Size([1])\n",
      "===bias===  Parameter containing:\n",
      "tensor([100.], requires_grad=True)\n",
      "===result===  tensor([[[103., 105.]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 2, bias.\n",
    "input = torch.tensor([1, 2, 3], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 2)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1, 1], dtype = torch.float32, requires_grad = True).view(layer.weight.shape))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "print(F\"===bias shape===  {layer.bias.shape}\")\n",
    "layer.bias = torch.nn.parameter.Parameter(torch.tensor([100], dtype = torch.float32, requires_grad = True))\n",
    "print(F\"===bias===  {layer.bias}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420f1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3., 4., 5.]]])\n",
      "===weight shape===  torch.Size([1, 1, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1.0000, 0.1100]]], requires_grad=True)\n",
      "===result===  tensor([[[1.2200, 3.4400]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 3, stride\n",
    "input = torch.tensor([1, 2, 3, 4, 5], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 2, bias = False, stride = 2)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1., 0.11], dtype = torch.float32, requires_grad = True).view(layer.weight.shape))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899ca5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3.]]])\n",
      "===weight shape===  torch.Size([1, 1, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1.0000, 0.1000]]], requires_grad=True)\n",
      "===result===  tensor([[[0.1000, 1.2000, 2.3000, 3.0000]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 4, padding, case 1, padding = 1\n",
    "input = torch.tensor([1, 2, 3], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 2, bias = False, padding = 1)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1., 0.1], dtype = torch.float32, requires_grad = True).view(1, 1, -1))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d935703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3.]]])\n",
      "===weight shape===  torch.Size([1, 1, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1.0000, 0.1000]]], requires_grad=True)\n",
      "===result===  tensor([[[0.0000, 0.1000, 1.2000, 2.3000, 3.0000, 0.0000]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 4, padding, case 2, padding = 2\n",
    "input = torch.tensor([1, 2, 3], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 2, bias = False, padding = 2)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1., 0.1], dtype = torch.float32, requires_grad = True).view(1, 1, -1))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e975707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[  1.,   2.],\n",
      "         [  4.,   8.],\n",
      "         [100., 200.],\n",
      "         [400., 800.]]])\n",
      "===weight shape===  torch.Size([2, 2, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1000.0000,  100.0000],\n",
      "         [  10.0000,    1.0000]],\n",
      "\n",
      "        [[   1.0000,    1.0100],\n",
      "         [   1.0101,    1.0101]]], requires_grad=True)\n",
      "===result===  tensor([[[1248.0000],\n",
      "         [1514.1207]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 5, groups. I don't know how this would help in any means. But it's there. \n",
    "input = torch.tensor([1, 2, 4, 8, 100, 200, 400, 800], dtype = torch.float32).view(1, 4, 2)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 4, out_channels = 2, kernel_size = 2, bias = False, groups = 2)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1000, 100, 10, 1., 1, 1.01, 1.0101, 1.010101], dtype = torch.float32, requires_grad = True).view(*layer.weight.shape))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "830e33e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3., 4., 5.]]])\n",
      "===weight shape===  torch.Size([1, 1, 2])\n",
      "===weight===  Parameter containing:\n",
      "tensor([[[1.0000, 0.1000]]], requires_grad=True)\n",
      "===result===  tensor([[[1.3000, 2.4000, 3.5000]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 6, dilation.\n",
    "input = torch.tensor([1, 2, 3, 4, 5], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 2, bias = False, dilation = 2)\n",
    "print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1., 0.1], dtype = torch.float32, requires_grad = True).view(*layer.weight.shape))\n",
    "print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6a8dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3.]]])\n",
      "===result===  tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 2., 3., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 7, padding mode, case 1, zeros. No limitation for the padding value.\n",
    "input = torch.tensor([1, 2, 3], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 1, bias = False, padding = 7, padding_mode = \"zeros\")\n",
    "#print(F\"===weight shape===  {layer.weight.shape}\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1.], dtype = torch.float32, requires_grad = True).view(1, 1, -1))\n",
    "#print(F\"===weight===  {layer.weight}\")\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83376d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3.]]])\n",
      "===result===  tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 2., 3., 3., 3., 3., 3., 3., 3., 3.]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 7, padding mode, case 2, replicate. No limitation for the padding value.\n",
    "input = torch.tensor([1, 2, 3], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 1, bias = False, padding = 7, padding_mode = \"replicate\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1.], dtype = torch.float32, requires_grad = True).view(1, 1, -1))\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74ce326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3., 4.]]])\n",
      "===result===  tensor([[[4., 3., 2., 1., 2., 3., 4., 3., 2., 1.]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 7, padding mode, case 3, reflect. Notice, the max padding value is the size of input - 1. \n",
    "#In this case, size of input is 4, the max padding value is 3.\n",
    "input = torch.tensor([1, 2, 3, 4], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 1, bias = False, padding = 3, padding_mode = \"reflect\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1.], dtype = torch.float32, requires_grad = True).view(1, 1, -1))\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42538b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===input===  tensor([[[1., 2., 3.]]])\n",
      "===result===  tensor([[[1., 2., 3., 1., 2., 3., 1., 2., 3.]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test 7, padding mode, case 4, circular. Notice, the max padding value is the same as size of input.\n",
    "#In this case, size of input is 3, the max padding value is also 3.\n",
    "input = torch.tensor([1, 2, 3], dtype = torch.float32).view(1, 1, -1)\n",
    "print(F\"===input===  {input}\")\n",
    "\n",
    "layer = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 1, bias = False, padding = 3, padding_mode = \"circular\")\n",
    "layer.weight = torch.nn.parameter.Parameter(torch.tensor([1.], dtype = torch.float32, requires_grad = True).view(1, 1, -1))\n",
    "\n",
    "print(F\"===result===  {layer(input)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
